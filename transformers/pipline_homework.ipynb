{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1918534e-e986-48b0-8ede-618fdece01ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:00:48.648501Z",
     "iopub.status.busy": "2024-02-13T08:00:48.648129Z",
     "iopub.status.idle": "2024-02-13T08:00:48.651402Z",
     "shell.execute_reply": "2024-02-13T08:00:48.650773Z",
     "shell.execute_reply.started": "2024-02-13T08:00:48.648477Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f2e3b-b05b-4511-a48f-79b68dc86464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:01:06.929202Z",
     "iopub.status.busy": "2024-02-13T08:01:06.928805Z",
     "iopub.status.idle": "2024-02-13T08:01:06.931905Z",
     "shell.execute_reply": "2024-02-13T08:01:06.931275Z",
     "shell.execute_reply.started": "2024-02-13T08:01:06.929182Z"
    }
   },
   "source": [
    "## Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9edc4-7693-4fbc-a2b0-09bd16af8296",
   "metadata": {},
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02fcbfaf-bd9a-4af8-bccb-bef2a2e08535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:03:27.026034Z",
     "iopub.status.busy": "2024-02-13T08:03:27.025587Z",
     "iopub.status.idle": "2024-02-13T08:03:27.249405Z",
     "shell.execute_reply": "2024-02-13T08:03:27.248785Z",
     "shell.execute_reply.started": "2024-02-13T08:03:27.026014Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8957217335700989}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"sentiment-analysis\")\n",
    "pipe(\"今儿上海可真冷啊\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8463e267-2e51-4701-a38c-28ddb33470ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:03:48.861812Z",
     "iopub.status.busy": "2024-02-13T08:03:48.861422Z",
     "iopub.status.idle": "2024-02-13T08:03:48.887754Z",
     "shell.execute_reply": "2024-02-13T08:03:48.887083Z",
     "shell.execute_reply.started": "2024-02-13T08:03:48.861792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8578691482543945}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认使用的模型 distilbert-base-uncased-finetuned-sst-2-english \n",
    "# 并未针对中文做太多训练，中文的文本分类任务表现未必满意\n",
    "pipe(\"你学东西真的好快，理论课一讲就明白了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8ef1732-4f63-4a57-8a6b-169932ef7c14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:14:18.197987Z",
     "iopub.status.busy": "2024-02-13T08:14:18.197636Z",
     "iopub.status.idle": "2024-02-13T08:14:37.520059Z",
     "shell.execute_reply": "2024-02-13T08:14:37.519385Z",
     "shell.execute_reply.started": "2024-02-13T08:14:18.197967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 759/759 [00:00<00:00, 4.48MB/s]\n",
      "model.safetensors: 100%|██████████| 541M/541M [00:18<00:00, 29.4MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 373/373 [00:00<00:00, 2.57MB/s]\n",
      "vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 36.5MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.92M/2.92M [00:00<00:00, 24.6MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 1.02MB/s]\n",
      "/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "new_pipe = pipeline(task=\"sentiment-analysis\"\n",
    "                    ,model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "                    , return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f11e9c8-791a-468e-983a-72d0e254119a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:15:08.072140Z",
     "iopub.status.busy": "2024-02-13T08:15:08.071743Z",
     "iopub.status.idle": "2024-02-13T08:15:08.097295Z",
     "shell.execute_reply": "2024-02-13T08:15:08.096759Z",
     "shell.execute_reply.started": "2024-02-13T08:15:08.072119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.9461327791213989},\n",
       "  {'label': 'neutral', 'score': 0.03845958411693573},\n",
       "  {'label': 'negative', 'score': 0.015407552011311054}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pipe(\"你学东西真的好快，理论课一讲就明白了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56db89-a4f8-41b8-96ac-f8f0a7a2b408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:17:59.951616Z",
     "iopub.status.busy": "2024-02-13T08:17:59.951352Z",
     "iopub.status.idle": "2024-02-13T08:17:59.954570Z",
     "shell.execute_reply": "2024-02-13T08:17:59.953915Z",
     "shell.execute_reply.started": "2024-02-13T08:17:59.951596Z"
    }
   },
   "source": [
    "### Token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1339a19-7ef2-443b-82a4-ca04702651e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:19:03.084508Z",
     "iopub.status.busy": "2024-02-13T08:19:03.084144Z",
     "iopub.status.idle": "2024-02-13T08:19:06.232694Z",
     "shell.execute_reply": "2024-02-13T08:19:06.232033Z",
     "shell.execute_reply.started": "2024-02-13T08:19:03.084488Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 998/998 [00:00<00:00, 7.65MB/s]\n",
      "model.safetensors: 100%|██████████| 1.33G/1.33G [00:02<00:00, 546MB/s]\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "tokenizer_config.json: 100%|██████████| 60.0/60.0 [00:00<00:00, 481kB/s]\n",
      "vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 51.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\")\n",
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a33d82-a8e9-454c-8dda-43d4847ac97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:20:28.428885Z",
     "iopub.status.busy": "2024-02-13T08:20:28.428504Z",
     "iopub.status.idle": "2024-02-13T08:20:34.431921Z",
     "shell.execute_reply": "2024-02-13T08:20:34.431358Z",
     "shell.execute_reply.started": "2024-02-13T08:20:28.428865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 852/852 [00:00<00:00, 6.72MB/s]\n",
      "model.safetensors: 100%|██████████| 2.24G/2.24G [00:03<00:00, 569MB/s]\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "sentencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 45.8MB/s]\n",
      "tokenizer.json: 100%|██████████| 9.10M/9.10M [00:00<00:00, 44.0MB/s]\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9999, 'index': 1, 'word': '▁Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9999, 'index': 2, 'word': 'gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9999, 'index': 3, 'word': '▁Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 1.0, 'index': 6, 'word': '▁French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 1.0, 'index': 10, 'word': '▁New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 1.0, 'index': 11, 'word': '▁York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 1.0, 'index': 12, 'word': '▁City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\",model=\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\")\n",
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9ab8220-26b9-4249-8599-f34c44e241a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:22:02.794911Z",
     "iopub.status.busy": "2024-02-13T08:22:02.794511Z",
     "iopub.status.idle": "2024-02-13T08:22:03.410214Z",
     "shell.execute_reply": "2024-02-13T08:22:03.409688Z",
     "shell.execute_reply.started": "2024-02-13T08:22:02.794889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9674637,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 0,\n",
       "  'end': 12},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.9982874,\n",
       "  'word': 'French',\n",
       "  'start': 18,\n",
       "  'end': 24},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99896103,\n",
       "  'word': 'New York City',\n",
       "  'start': 42,\n",
       "  'end': 55}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\", grouped_entities=True)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d41ac90-54e3-4b5d-8922-a4832b086814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:22:33.396750Z",
     "iopub.status.busy": "2024-02-13T08:22:33.396217Z",
     "iopub.status.idle": "2024-02-13T08:22:34.815032Z",
     "shell.execute_reply": "2024-02-13T08:22:34.814498Z",
     "shell.execute_reply.started": "2024-02-13T08:22:33.396728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.9999173,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 0,\n",
       "  'end': 12},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.9999932,\n",
       "  'word': 'French',\n",
       "  'start': 18,\n",
       "  'end': 24},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99999696,\n",
       "  'word': 'New York City',\n",
       "  'start': 42,\n",
       "  'end': 55}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\",model=\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\",grouped_entities=True)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86100d3-66b0-4416-9f5a-6b3c9e3f2344",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca3150f1-d49f-4ce4-838f-b43a6b60cdd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:27:30.165534Z",
     "iopub.status.busy": "2024-02-13T08:27:30.165177Z",
     "iopub.status.idle": "2024-02-13T08:27:31.991878Z",
     "shell.execute_reply": "2024-02-13T08:27:31.991317Z",
     "shell.execute_reply.started": "2024-02-13T08:27:30.165514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 473/473 [00:00<00:00, 3.65MB/s]\n",
      "model.safetensors: 100%|██████████| 261M/261M [00:00<00:00, 440MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 245kB/s]\n",
      "vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 68.2MB/s]\n",
      "tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 29.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(task=\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38be0fc0-806a-4d58-ae3b-069ba06a3a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:27:33.052408Z",
     "iopub.status.busy": "2024-02-13T08:27:33.052072Z",
     "iopub.status.idle": "2024-02-13T08:27:33.082432Z",
     "shell.execute_reply": "2024-02-13T08:27:33.081884Z",
     "shell.execute_reply.started": "2024-02-13T08:27:33.052389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9327, start: 30, end: 54, answer: huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e07da-b862-4dbe-9723-9cba294c3f35",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d48e22-09b1-4f47-8dd2-a3775f913ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:30:16.996034Z",
     "iopub.status.busy": "2024-02-13T08:30:16.995666Z",
     "iopub.status.idle": "2024-02-13T08:30:21.096926Z",
     "shell.execute_reply": "2024-02-13T08:30:21.096370Z",
     "shell.execute_reply.started": "2024-02-13T08:30:16.996013Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 1.80k/1.80k [00:00<00:00, 11.9MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.22G/1.22G [00:02<00:00, 584MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 198kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 43.9MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 59.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "base_summarizer = pipeline(task=\"summarization\")\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"t5-base\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d728018a-e003-493f-9c62-1231a6951c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:31:10.670515Z",
     "iopub.status.busy": "2024-02-13T08:31:10.670134Z",
     "iopub.status.idle": "2024-02-13T08:31:13.979167Z",
     "shell.execute_reply": "2024-02-13T08:31:13.978616Z",
     "shell.execute_reply.started": "2024-02-13T08:31:10.670495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The Transformer is the first sequence transduction model based entirely on attention . It replaces the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention . For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers .'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text =    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    "base_summarizer(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01fe59b7-9a65-4292-8e5b-682384df9368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:31:29.485694Z",
     "iopub.status.busy": "2024-02-13T08:31:29.485284Z",
     "iopub.status.idle": "2024-02-13T08:31:31.154082Z",
     "shell.execute_reply": "2024-02-13T08:31:31.153531Z",
     "shell.execute_reply.started": "2024-02-13T08:31:29.485675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decode'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159b583-32b7-468c-836d-e3a0d56ec077",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b9f7784-6bde-4486-882d-eba5b97372b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:34:35.860375Z",
     "iopub.status.busy": "2024-02-13T08:34:35.860028Z",
     "iopub.status.idle": "2024-02-13T08:34:37.469859Z",
     "shell.execute_reply": "2024-02-13T08:34:37.469324Z",
     "shell.execute_reply.started": "2024-02-13T08:34:35.860355Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/__init__.py:1049: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"Hugging Face est une tribune communautaire de l'apprentissage des machines.\"}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"translate English to French: Hugging Face is a community-based open-source platform for machine learning.\"\n",
    "translator = pipeline(task=\"translation\", model=\"t5-small\")\n",
    "translator(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c558f62-474a-427a-9b6c-25a22ec27852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:37:15.079969Z",
     "iopub.status.busy": "2024-02-13T08:37:15.079516Z",
     "iopub.status.idle": "2024-02-13T08:37:15.554824Z",
     "shell.execute_reply": "2024-02-13T08:37:15.554245Z",
     "shell.execute_reply.started": "2024-02-13T08:37:15.079949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Hugging Face ist eine kommunale Open-Source-Plattform für maschinelles Lernen.'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"translate English to Chinese: Hugging Face is a community-based open-source platform for machine learning.\"\n",
    "translator(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d27a32-0811-49ba-b2a3-77ececad3ddd",
   "metadata": {},
   "source": [
    "### Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afe654d3-3077-44f7-9d34-e5fe84870862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:40:06.677065Z",
     "iopub.status.busy": "2024-02-13T08:40:06.676684Z",
     "iopub.status.idle": "2024-02-13T08:40:09.945880Z",
     "shell.execute_reply": "2024-02-13T08:40:09.945361Z",
     "shell.execute_reply.started": "2024-02-13T08:40:06.677045Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 665/665 [00:00<00:00, 4.66MB/s]\n",
      "model.safetensors: 100%|██████████| 548M/548M [00:00<00:00, 558MB/s] \n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 1.03MB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 44.9MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 36.6MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 11.5MB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hugging Face is a community-based open-source platform for machine learning. The goal is to give machine learning a platform, and not a place to hide behind. That's the message behind it and my primary goal is to keep the community on\"}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Hugging Face is a community-based open-source platform for machine learning.\"\n",
    "generator = pipeline(task=\"text-generation\")\n",
    "generator(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "973222b7-6ee9-4557-913b-750ff78d2307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:42:10.073131Z",
     "iopub.status.busy": "2024-02-13T08:42:10.072693Z",
     "iopub.status.idle": "2024-02-13T08:42:11.578948Z",
     "shell.execute_reply": "2024-02-13T08:42:11.578292Z",
     "shell.execute_reply.started": "2024-02-13T08:42:10.073111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 480/480 [00:00<00:00, 3.38MB/s]\n",
      "model.safetensors: 100%|██████████| 331M/331M [00:00<00:00, 578MB/s] \n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 30.2MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 5.35MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 44.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2236,\n",
       "  'token': 1761,\n",
       "  'token_str': ' platform',\n",
       "  'sequence': 'Hugging Face is a community-based open-source platform for machine learning.'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hugging Face is a community-based open-source <mask> for machine learning.\"\n",
    "fill_mask = pipeline(task=\"fill-mask\")\n",
    "preds = fill_mask(text, top_k=1)\n",
    "preds = [\n",
    "    {\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"token\": pred[\"token\"],\n",
    "        \"token_str\": pred[\"token_str\"],\n",
    "        \"sequence\": pred[\"sequence\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f030f129-faa8-4b76-aa97-1538f008d1bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:01:27.167481Z",
     "iopub.status.busy": "2024-02-13T08:01:27.167076Z",
     "iopub.status.idle": "2024-02-13T08:01:27.170158Z",
     "shell.execute_reply": "2024-02-13T08:01:27.169566Z",
     "shell.execute_reply.started": "2024-02-13T08:01:27.167441Z"
    }
   },
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568e78d-85ca-4d95-b734-9db686fbe4b0",
   "metadata": {},
   "source": [
    "### Audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ede011-e1ae-4406-bb46-c53c000bb279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T16:15:21.864729Z",
     "iopub.status.busy": "2024-02-13T16:15:21.864399Z",
     "iopub.status.idle": "2024-02-13T16:15:25.013030Z",
     "shell.execute_reply": "2024-02-13T16:15:25.012293Z",
     "shell.execute_reply.started": "2024-02-13T16:15:21.864710Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at superb/hubert-base-superb-er were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_v', 'hubert.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at superb/hubert-base-superb-er and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ffmpeg was not found but is required to load audio files from filename",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/audio_classification.py:54\u001b[0m, in \u001b[0;36mffmpeg_read\u001b[0;34m(bpayload, sampling_rate)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     ffmpeg_process \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mffmpeg_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuperb/hubert-base-superb-er\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m preds \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m4\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m preds]\n\u001b[1;32m      6\u001b[0m preds\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/audio_classification.py:136\u001b[0m, in \u001b[0;36mAudioClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    105\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    107\u001b[0m ):\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    Classify the sequence(s) given as inputs. See the [`AutomaticSpeechRecognitionPipeline`] documentation for more\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        - **score** (`float`) -- The corresponding probability.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/base.py:1146\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m-> 1146\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[1;32m   1148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/audio_classification.py:158\u001b[0m, in \u001b[0;36mAudioClassificationPipeline.preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m             inputs \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m--> 158\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Accepting `\"array\"` which is the key defined in `datasets` for\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# better integration\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs)):\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/transformers/pipelines/audio_classification.py:56\u001b[0m, in \u001b[0;36mffmpeg_read\u001b[0;34m(bpayload, sampling_rate)\u001b[0m\n\u001b[1;32m     54\u001b[0m     ffmpeg_process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(ffmpeg_command, stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg was not found but is required to load audio files from filename\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m output_stream \u001b[38;5;241m=\u001b[39m ffmpeg_process\u001b[38;5;241m.\u001b[39mcommunicate(bpayload)\n\u001b[1;32m     58\u001b[0m out_bytes \u001b[38;5;241m=\u001b[39m output_stream[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: ffmpeg was not found but is required to load audio files from filename"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")\n",
    "preds = classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93354ba2-6026-4e6e-a42a-b6046bedb63e",
   "metadata": {},
   "source": [
    "### Automatic speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4359c2-ee8d-41a4-a2ae-5cbd4f80f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccd363-296c-46d1-8e82-a83ec44298d9",
   "metadata": {},
   "source": [
    "## Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42059e3-21fe-4585-a8e9-1a0507e2bc2c",
   "metadata": {},
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a4a990c-3567-4bb8-8f21-aa3d817dc939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:49:02.916676Z",
     "iopub.status.busy": "2024-02-13T08:49:02.916235Z",
     "iopub.status.idle": "2024-02-13T08:49:04.154521Z",
     "shell.execute_reply": "2024-02-13T08:49:04.153867Z",
     "shell.execute_reply.started": "2024-02-13T08:49:02.916656Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 69.7k/69.7k [00:00<00:00, 63.0MB/s]\n",
      "model.safetensors: 100%|██████████| 346M/346M [00:00<00:00, 564MB/s] \n",
      "preprocessor_config.json: 100%|██████████| 160/160 [00:00<00:00, 1.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "{'score': 0.0229, 'label': 'tiger cat'}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"image-classification\")\n",
    "preds = classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25443d42-765c-4d3c-87a6-2ada7136d57e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:49:21.889381Z",
     "iopub.status.busy": "2024-02-13T08:49:21.888749Z",
     "iopub.status.idle": "2024-02-13T08:49:22.101531Z",
     "shell.execute_reply": "2024-02-13T08:49:22.100902Z",
     "shell.execute_reply.started": "2024-02-13T08:49:21.889351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "{'score': 0.0229, 'label': 'tiger cat'}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\n",
    "    \"data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93df21b-97d4-4cf5-94be-aa342046a85d",
   "metadata": {},
   "source": [
    "### Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fd3dda0-3f0c-462f-a388-2e66c53172b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:50:25.253915Z",
     "iopub.status.busy": "2024-02-13T08:50:25.253557Z",
     "iopub.status.idle": "2024-02-13T08:50:28.481855Z",
     "shell.execute_reply": "2024-02-13T08:50:28.481206Z",
     "shell.execute_reply.started": "2024-02-13T08:50:25.253895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 2729413 (https://huggingface.co/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 4.59k/4.59k [00:00<00:00, 30.9MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 167M/167M [00:00<00:00, 384MB/s] \n",
      "model.safetensors: 100%|██████████| 102M/102M [00:00<00:00, 500MB/s] \n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "preprocessor_config.json: 100%|██████████| 274/274 [00:00<00:00, 2.18MB/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9864,\n",
       "  'label': 'cat',\n",
       "  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = pipeline(task=\"object-detection\")\n",
    "preds = detector(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96844d92-5636-4592-85a9-96169beb5af2",
   "metadata": {},
   "source": [
    "### Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "611f0b7d-6959-48c5-b1c5-b5a356fb1295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:51:18.552198Z",
     "iopub.status.busy": "2024-02-13T08:51:18.551758Z",
     "iopub.status.idle": "2024-02-13T08:51:22.730057Z",
     "shell.execute_reply": "2024-02-13T08:51:22.729410Z",
     "shell.execute_reply.started": "2024-02-13T08:51:18.552176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50-panoptic and revision fc15262 (https://huggingface.co/facebook/detr-resnet-50-panoptic).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 11.6k/11.6k [00:00<00:00, 63.3MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 172M/172M [00:00<00:00, 327MB/s]  \n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50-panoptic were not used when initializing DetrForSegmentation: ['detr.model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'detr.model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "preprocessor_config.json: 100%|██████████| 273/273 [00:00<00:00, 1.82MB/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "`label_ids_to_fuse` unset. No instance will be fused.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9879, 'label': 'LABEL_184'}\n",
      "{'score': 0.9973, 'label': 'snow'}\n",
      "{'score': 0.9972, 'label': 'cat'}\n"
     ]
    }
   ],
   "source": [
    "segmenter = pipeline(task=\"image-segmentation\")\n",
    "preds = segmenter(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d38645-b05d-4e87-b24e-a68e64d63cb4",
   "metadata": {},
   "source": [
    "### Depth estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de9177ec-50ab-414d-aa48-db845106f5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:52:25.180574Z",
     "iopub.status.busy": "2024-02-13T08:52:25.180176Z",
     "iopub.status.idle": "2024-02-13T08:52:31.169883Z",
     "shell.execute_reply": "2024-02-13T08:52:31.169312Z",
     "shell.execute_reply.started": "2024-02-13T08:52:25.180553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to Intel/dpt-large and revision e93beec (https://huggingface.co/Intel/dpt-large).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 942/942 [00:00<00:00, 7.25MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.37G/1.37G [00:02<00:00, 524MB/s] \n",
      "Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "preprocessor_config.json: 100%|██████████| 285/285 [00:00<00:00, 2.09MB/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "depth_estimator = pipeline(task=\"depth-estimation\")\n",
    "preds = depth_estimator(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c9de7f7-9333-4737-87b0-b09eecb7dd1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:52:34.594991Z",
     "iopub.status.busy": "2024-02-13T08:52:34.594618Z",
     "iopub.status.idle": "2024-02-13T08:52:34.600479Z",
     "shell.execute_reply": "2024-02-13T08:52:34.599915Z",
     "shell.execute_reply.started": "2024-02-13T08:52:34.594971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_depth': tensor([[[ 0.7999,  0.8382,  0.8483,  ...,  2.3091,  2.3669,  2.3291],\n",
       "          [ 0.8055,  0.8101,  0.8106,  ...,  2.3390,  2.3357,  2.3308],\n",
       "          [ 0.8580,  0.8359,  0.8457,  ...,  2.3557,  2.3509,  2.3599],\n",
       "          ...,\n",
       "          [26.3410, 26.4059, 26.3881,  ..., 17.5088, 17.4768, 17.4148],\n",
       "          [26.4727, 26.4515, 26.5042,  ..., 17.4222, 17.3910, 17.4052],\n",
       "          [26.5116, 26.5452, 26.5301,  ..., 17.4719, 17.4700, 17.4025]]]),\n",
       " 'depth': <PIL.Image.Image image mode=L size=960x686>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed15f1-0c7a-4519-84ac-6b50b31f6366",
   "metadata": {},
   "source": [
    "## Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fd3ca-38f0-4da0-9799-0e13655c064b",
   "metadata": {},
   "source": [
    "### Document question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4216086a-432c-4785-99b9-a2d3462c2bf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T08:53:11.096987Z",
     "iopub.status.busy": "2024-02-13T08:53:11.096549Z",
     "iopub.status.idle": "2024-02-13T08:53:11.346236Z",
     "shell.execute_reply": "2024-02-13T08:53:11.345532Z",
     "shell.execute_reply.started": "2024-02-13T08:53:11.096967Z"
    }
   },
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x7f21da5bdbc0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://datasets-server.huggingface.co/assets/hf-internal-testing/example-documents/--/hf-internal-testing--example-documents/test/2/image/image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m doc_question_answerer \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument-question-answering\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmagorshunov/layoutlm-invoices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m preds \u001b[38;5;241m=\u001b[39m doc_question_answerer(\n\u001b[1;32m     10\u001b[0m     question\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the total amount?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     image\u001b[38;5;241m=\u001b[39mimage,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.10/site-packages/PIL/Image.py:3309\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3307\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3308\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3309\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f21da5bdbc0>"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://datasets-server.huggingface.co/assets/hf-internal-testing/example-documents/--/hf-internal-testing--example-documents/test/2/image/image.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "doc_question_answerer = pipeline(\"document-question-answering\", model=\"magorshunov/layoutlm-invoices\")\n",
    "preds = doc_question_answerer(\n",
    "    question=\"What is the total amount?\",\n",
    "    image=image,\n",
    ")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f629f-2e14-4fd2-8efc-858b84e0ab4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
